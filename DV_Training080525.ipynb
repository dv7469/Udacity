{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9acfaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install twine==3.8.0\n",
    "#pip show twine\n",
    "!pip install workspace_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86b15f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check torch version and CUDA status if GPU is enabled.\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "#from workspace_utils import active_session\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available()) # Should return True when GPU is enabled. \n",
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95941023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 13 13\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "#image_datasets = \n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=test_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "print(len(trainloader),len(testloader),len(validloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f871633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    unique_ids = set(item for item in cat_to_name)\n",
    "    OutputSize=len(unique_ids)\n",
    "    print(OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c4b5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #USE CUDA if available\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae26643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (fc2): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    (fc3): Linear(in_features=1000, out_features=102, bias=True)\n",
      "    (output): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)#Pre-determined 20588 Inputs\n",
    "#model = models.densenet121(pretrained=True) \n",
    "#model = models.resnet50(pretrained=True)\n",
    "# Freeze parameters so we don't backprop through them--OPTION2\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "classifier=nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088,4096)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(p=0.3)),\n",
    "    ('fc2', nn.Linear(4096,1000)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(p=0.3)),\n",
    "    ('fc3', nn.Linear(1000,OutputSize)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "    ]))\n",
    "\n",
    "model.classifier=classifier\n",
    "criterion=nn.NLLLoss()\n",
    "optimizer=optim.Adam(model.classifier.parameters(), lr=0.0003)\n",
    "model.to(device);\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17f80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. \n",
      "TRAINING_LOOP::: 1\n",
      "TRAINING_LOOP::: 2\n",
      "TRAINING_LOOP::: 3\n",
      "TRAINING_LOOP::: 4\n",
      "TRAINING_LOOP::: 5\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 4.667.. Test loss: 4.269.. Test accuracy: 0.163\n",
      "TRAINING_LOOP::: 6\n",
      "TRAINING_LOOP::: 7\n",
      "TRAINING_LOOP::: 8\n",
      "TRAINING_LOOP::: 9\n",
      "TRAINING_LOOP::: 10\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 4.202.. Test loss: 3.508.. Test accuracy: 0.236\n",
      "TRAINING_LOOP::: 11\n",
      "TRAINING_LOOP::: 12\n",
      "TRAINING_LOOP::: 13\n",
      "TRAINING_LOOP::: 14\n",
      "TRAINING_LOOP::: 15\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 3.658.. Test loss: 3.018.. Test accuracy: 0.304\n",
      "TRAINING_LOOP::: 16\n",
      "TRAINING_LOOP::: 17\n",
      "TRAINING_LOOP::: 18\n",
      "TRAINING_LOOP::: 19\n",
      "TRAINING_LOOP::: 20\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 3.343.. Test loss: 2.602.. Test accuracy: 0.388\n",
      "TRAINING_LOOP::: 21\n",
      "TRAINING_LOOP::: 22\n",
      "TRAINING_LOOP::: 23\n",
      "TRAINING_LOOP::: 24\n",
      "TRAINING_LOOP::: 25\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 2.823.. Test loss: 2.323.. Test accuracy: 0.474\n",
      "TRAINING_LOOP::: 26\n",
      "TRAINING_LOOP::: 27\n",
      "TRAINING_LOOP::: 28\n",
      "TRAINING_LOOP::: 29\n",
      "TRAINING_LOOP::: 30\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 2.695.. Test loss: 1.959.. Test accuracy: 0.510\n",
      "TRAINING_LOOP::: 31\n",
      "TRAINING_LOOP::: 32\n",
      "TRAINING_LOOP::: 33\n",
      "TRAINING_LOOP::: 34\n",
      "TRAINING_LOOP::: 35\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 2.317.. Test loss: 1.700.. Test accuracy: 0.554\n",
      "TRAINING_LOOP::: 36\n",
      "TRAINING_LOOP::: 37\n",
      "TRAINING_LOOP::: 38\n",
      "TRAINING_LOOP::: 39\n",
      "TRAINING_LOOP::: 40\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 2.138.. Test loss: 1.567.. Test accuracy: 0.600\n",
      "TRAINING_LOOP::: 41\n",
      "TRAINING_LOOP::: 42\n",
      "TRAINING_LOOP::: 43\n",
      "TRAINING_LOOP::: 44\n",
      "TRAINING_LOOP::: 45\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.873.. Test loss: 1.457.. Test accuracy: 0.619\n",
      "TRAINING_LOOP::: 46\n",
      "TRAINING_LOOP::: 47\n",
      "TRAINING_LOOP::: 48\n",
      "TRAINING_LOOP::: 49\n",
      "TRAINING_LOOP::: 50\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.625.. Test loss: 1.287.. Test accuracy: 0.659\n",
      "TRAINING_LOOP::: 51\n",
      "TRAINING_LOOP::: 52\n",
      "TRAINING_LOOP::: 53\n",
      "TRAINING_LOOP::: 54\n",
      "TRAINING_LOOP::: 55\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.547.. Test loss: 1.287.. Test accuracy: 0.648\n",
      "TRAINING_LOOP::: 56\n",
      "TRAINING_LOOP::: 57\n",
      "TRAINING_LOOP::: 58\n",
      "TRAINING_LOOP::: 59\n",
      "TRAINING_LOOP::: 60\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.547.. Test loss: 1.151.. Test accuracy: 0.677\n",
      "TRAINING_LOOP::: 61\n",
      "TRAINING_LOOP::: 62\n",
      "TRAINING_LOOP::: 63\n",
      "TRAINING_LOOP::: 64\n",
      "TRAINING_LOOP::: 65\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.840.. Test loss: 1.078.. Test accuracy: 0.701\n",
      "TRAINING_LOOP::: 66\n",
      "TRAINING_LOOP::: 67\n",
      "TRAINING_LOOP::: 68\n",
      "TRAINING_LOOP::: 69\n",
      "TRAINING_LOOP::: 70\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.441.. Test loss: 1.016.. Test accuracy: 0.732\n",
      "TRAINING_LOOP::: 71\n",
      "TRAINING_LOOP::: 72\n",
      "TRAINING_LOOP::: 73\n",
      "TRAINING_LOOP::: 74\n",
      "TRAINING_LOOP::: 75\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.444.. Test loss: 1.017.. Test accuracy: 0.710\n",
      "TRAINING_LOOP::: 76\n",
      "TRAINING_LOOP::: 77\n",
      "TRAINING_LOOP::: 78\n",
      "TRAINING_LOOP::: 79\n",
      "TRAINING_LOOP::: 80\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.328.. Test loss: 0.914.. Test accuracy: 0.750\n",
      "TRAINING_LOOP::: 81\n",
      "TRAINING_LOOP::: 82\n",
      "TRAINING_LOOP::: 83\n",
      "TRAINING_LOOP::: 84\n",
      "TRAINING_LOOP::: 85\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.314.. Test loss: 0.977.. Test accuracy: 0.726\n",
      "TRAINING_LOOP::: 86\n",
      "TRAINING_LOOP::: 87\n",
      "TRAINING_LOOP::: 88\n",
      "TRAINING_LOOP::: 89\n",
      "TRAINING_LOOP::: 90\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.274.. Test loss: 1.071.. Test accuracy: 0.710\n",
      "TRAINING_LOOP::: 91\n",
      "TRAINING_LOOP::: 92\n",
      "TRAINING_LOOP::: 93\n",
      "TRAINING_LOOP::: 94\n",
      "TRAINING_LOOP::: 95\n",
      "EVAL_LOOP::\n",
      "Epoch 1/1.. Train loss: 1.394.. Test loss: 0.806.. Test accuracy: 0.767\n",
      "TRAINING_LOOP::: 96\n",
      "TRAINING_LOOP::: 97\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "for epoch in range(epochs):\n",
    "    steps = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \") \n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        print(\"TRAINING_LOOP:::\",steps)\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            print(\"EVAL_LOOP::\")\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "\n",
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
    "#Save the checkpoint \n",
    "model.class_to_idx=train_data.class_to_idx\n",
    "checkpoint={'input_size':25088,\n",
    "            'output_size':OutputSize,\n",
    "            'epochs':1,\n",
    "            'mapping_class_to_idx':model.class_to_idx,\n",
    "            'optimizer_state':optimizer.state_dict(),\n",
    "            'state_dict':model.state_dict(),\n",
    "            'classifier':model.classifier}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint_dv.pth')\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782d762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
